{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte Carlo Simulation, Central Limit Theorem and Hypothesis Tesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### purpose of this assignment\n",
    "- Implement Monte Carlo simulation.\n",
    "- Observe and understand the Central Limit Theorem in action.\n",
    "- Understanding how hypothesis testing can help in analyzing data and making decisions based on it in different situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  piCalculation import *\n",
    "from menschGame import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, expon, uniform\n",
    "from scipy import stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Monte Carlo Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Pi Calculation\n",
    "This following code is an implementation of the Monte Carlo method to estimate the value of `pi`. The code generates a specified number of random points within a square, and then checks if each point is within a circle with a radius equal to the half of the square's side. The ratio of points inside the circle is then multiplied by 4 to get an estimate of the value of `pi`. The main function generates random points, estimates `pi`, and prints the result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 100000\n",
    "square_side = 2\n",
    "points = generate_points(num_points, square_side)\n",
    "pi_estimate = estimate_pi(points, square_side)\n",
    "print(f\"Estimated value of Pi: {pi_estimate}\")\n",
    "print(f\"Accuracy: {round(100 - abs(math.pi - pi_estimate) / math.pi * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Mensch Game\n",
    "I defines three classes: `Peg`, `Mensch` and `Mensch_Simulation`.\n",
    "\n",
    "#### Mensch Class:\n",
    "\n",
    "The `Mensch` class seems to be a representation of a game (possibly a simplified version of a board game similar to Ludo). Here's a breakdown of its main components:\n",
    "\n",
    "- **Attributes**:\n",
    "  - `_num_player`: Number of players in the game.\n",
    "  - `_players`: A list of player objects initialized with positions based on the number of boxes.\n",
    "  - `_current_player` and `_previous_player`: Keeps track of the current and previous player.\n",
    "  - `_winner`: Holds the label of the winning player.\n",
    "  - `_last_box`: Position of the last box on the board.\n",
    "  - `_next_player`: A generator function to determine the next player's turn.\n",
    "\n",
    "- **Methods**:\n",
    "  - `_roll_dice()`: Simulates rolling a dice and returns a number between 1 and 6.\n",
    "  - `_next_turn()`: A generator function that cycles through players to determine whose turn it is.\n",
    "  - `print_result(dice)`: Prints the current player, all players, and the dice roll.\n",
    "  - `_check_boxes()`: Checks for collisions between players and handles player movement and restarts.\n",
    "  - `run()`: Main game loop that iterates until a winner is determined.\n",
    "\n",
    "#### Mensch_Simulation Class:\n",
    "\n",
    "The `Mensch_Simulation` class is designed to simulate multiple games of `Mensch` and collect statistics on the winners:\n",
    "\n",
    "- **Attributes**:\n",
    "  - `num_game`: Number of games to simulate.\n",
    "\n",
    "- **Methods**:\n",
    "  - `run()`: Initializes a single `Mensch` game and returns the winner.\n",
    "  - `simulate()`: Runs multiple games and returns a `Counter` object that counts the number of times each player wins.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Mensch_Simulation(100000)\n",
    "test.simulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Central Limit Theorem(CLT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code demonstrates the Central Limit Theorem (CLT) through simulation. Here's a brief summary of what the code does:\n",
    "\n",
    "1. **Initialization**:\n",
    "    - `num_samples`: Number of sample means to generate for each sample size.\n",
    "    - `sample_sizes`: List of sample sizes to analyze.\n",
    "    - `distributions`: List of distributions to analyze (normal, exponential, and uniform).\n",
    "    - `xlim_ranges`: List of x-axis limits for each distribution.\n",
    "\n",
    "2. **Functions**:\n",
    "    - `generate_sample_means(distribution, sample_size)`: Generates `num_samples` sample means from a given distribution and sample size.\n",
    "    - `plot_sample_means(sample_means, sample_size, distribution, xlim_range)`: Plots the histogram of sample means and the expected normal distribution curve.\n",
    "\n",
    "3. **Simulation**:\n",
    "    - For each distribution (`norm`, `expon`, `uniform`):\n",
    "        - For each sample size in `sample_sizes`:\n",
    "            - Generate `num_samples` sample means using the `generate_sample_means` function.\n",
    "            - Plot the histogram of these sample means and overlay the expected normal distribution curve using the `plot_sample_means` function.\n",
    "\n",
    "4. **Visualization**:\n",
    "    - The code plots histograms of sample means along with the expected normal distribution curve for each distribution and sample size combination, demonstrating how the sample means approach a normal distribution as the sample size increases, consistent with the Central Limit Theorem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "sample_sizes = [10, 100, 500]\n",
    "\n",
    "def generate_sample_means(distribution, sample_size):\n",
    "    sample_means = []\n",
    "    for _ in range(num_samples):\n",
    "        sample = distribution.rvs(size=sample_size)\n",
    "        sample_means.append(np.mean(sample))\n",
    "    return sample_means\n",
    "\n",
    "def plot_sample_means(sample_means, sample_size, distribution, xlim_range):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(sample_means, bins=30, density=True, alpha=0.6, color='g', label='Sample Means Histogram')\n",
    "    \n",
    "    mu = np.mean(sample_means)\n",
    "    sigma = np.std(sample_means)\n",
    "    \n",
    "    x = np.linspace(min(sample_means), max(sample_means), 100)\n",
    "    plt.plot(x, norm.pdf(x, mu, sigma), 'r-', label='Expected Normal Distribution')\n",
    "    \n",
    "    plt.xlim(xlim_range)\n",
    "    plt.title(f'Sample Size: {sample_size}, Distribution: {distribution.name}')\n",
    "    plt.xlabel('Sample Means')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "distributions = [norm, expon, uniform]\n",
    "xlim_ranges = [[-1, 1], [0, 2], [0.2, 0.8]]\n",
    "for distribution, xlim_range in zip(distributions, xlim_ranges):\n",
    "    print(f\"Analyzing {distribution.name} distribution...\")\n",
    "    for sample_size in sample_sizes:\n",
    "        sample_means = generate_sample_means(distribution, sample_size)\n",
    "        plot_sample_means(sample_means, sample_size, distribution, xlim_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Unfair Coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Size: 30\n",
      "P:  0.5333333333333333\n",
      "confidence interval:  (0.354808679988615, 0.7118579866780517)\n",
      "Simulation: Z-Score = 0.3651, P-Value = 0.7150, Confidence Decision = Accept H0 (fair), P-Value Decision = Accept H0 (fair)\n",
      "\n",
      "Sample Size: 100\n",
      "P:  0.5\n",
      "confidence interval:  (0.402, 0.598)\n",
      "Simulation: Z-Score = 0.0000, P-Value = 1.0000, Confidence Decision = Accept H0 (fair), P-Value Decision = Accept H0 (fair)\n",
      "\n",
      "Sample Size: 1000\n",
      "P:  0.55\n",
      "confidence interval:  (0.5191650198637976, 0.5808349801362025)\n",
      "Simulation: Z-Score = 3.1623, P-Value = 0.0016, Confidence Decision = Reject H0 (unfair), P-Value Decision = Reject H0 (unfair)\n"
     ]
    }
   ],
   "source": [
    "p_heads_unfair = 0.55\n",
    "\n",
    "sample_sizes = [30, 100, 1000]\n",
    "\n",
    "num_simulations = 1000\n",
    "\n",
    "def simulate_coin_flips(p_heads, num_flips):\n",
    "    return np.random.choice(['H', 'T'], size=num_flips, p=[p_heads, 1-p_heads])\n",
    "\n",
    "\n",
    "for n in sample_sizes:\n",
    "    print(f\"\\nSample Size: {n}\")\n",
    "    flips = simulate_coin_flips(p_heads_unfair, n)\n",
    "    num_heads = np.sum(flips == 'H')\n",
    "    \n",
    "    p_hat = num_heads / n\n",
    "\n",
    "    z_score = (p_hat - 0.5) / np.sqrt(0.5 * 0.5 / n)\n",
    "    p_value = 2 * (norm.sf(abs(z_score))) \n",
    "    \n",
    "    margin_of_error = 1.96 * np.sqrt(p_hat * (1 - p_hat) / n)\n",
    "    confidence_interval = (p_hat - margin_of_error, p_hat + margin_of_error)\n",
    "    \n",
    "    if confidence_interval[0] <= 0.5 <= confidence_interval[1]:\n",
    "        confidence_decision = \"Accept H0 (fair)\"\n",
    "    else:\n",
    "        confidence_decision = \"Reject H0 (unfair)\"\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        p_value_decision = \"Reject H0 (unfair)\"\n",
    "    else:\n",
    "        p_value_decision = \"Accept H0 (fair)\"\n",
    "    print(\"P: \", p_hat)\n",
    "    print(\"confidence interval: \", confidence_interval)\n",
    "    print(f\"Simulation: Z-Score = {z_score:.4f}, P-Value = {p_value:.4f}, \"\n",
    "            f\"Confidence Decision = {confidence_decision}, P-Value Decision = {p_value_decision}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "\n",
    "#### 1. Z-Scores and P-Values:\n",
    "\n",
    "- **Sample Size of 30**: \n",
    "  - The z-score is \\(0.3651\\) and the p-value is \\(0.7150\\).\n",
    "  - The z-score is relatively small, indicating that the observed sample proportion is close to the expected proportion under the null hypothesis.\n",
    "  - The p-value is greater than \\(0.05\\), indicating that we fail to reject the null hypothesis at the \\(0.05\\) significance level.\n",
    "  \n",
    "- **Sample Size of 100**: \n",
    "  - The z-score is \\(0.0000\\) and the p-value is \\(1.0000\\).\n",
    "  - The z-score is exactly \\(0\\), indicating that the observed sample proportion is exactly equal to the expected proportion under the null hypothesis.\n",
    "  - The p-value is \\(1.0000\\), which is much greater than \\(0.05\\), confirming that we fail to reject the null hypothesis.\n",
    "  \n",
    "- **Sample Size of 1000**: \n",
    "  - The z-score is \\(3.1623\\) and the p-value is \\(0.0016\\).\n",
    "  - The z-score is relatively large, indicating that the observed sample proportion deviates significantly from the expected proportion under the null hypothesis.\n",
    "  - The p-value is less than \\(0.05\\), indicating that we reject the null hypothesis at the \\(0.05\\) significance level.\n",
    "\n",
    "#### 2. Decisions Regarding Null Hypothesis:\n",
    "\n",
    "- For **Sample Size of 30** and **Sample Size of 100**, the decisions based on both confidence intervals and p-values are to **Accept \\(H_0\\) (fair)**.\n",
    "  \n",
    "- For **Sample Size of 1000**, the decisions based on both confidence intervals and p-values are to **Reject \\(H_0\\) (unfair)**.\n",
    "\n",
    "#### 3. Impact of Sample Size:\n",
    "\n",
    "- **Increasing Sample Size**: As the sample size increases from 30 to 1000, the z-score becomes larger and the p-value becomes smaller when comparing the observed sample proportion to the expected proportion under the null hypothesis. This indicates that larger sample sizes provide more power to detect differences from the null hypothesis, making it easier to reject the null hypothesis when it is false.\n",
    "  \n",
    "- **Accuracy and Precision**: With larger sample sizes, the confidence intervals become narrower, providing a more precise estimate of the population proportion.\n",
    "  \n",
    "- **Statistical Significance**: A larger sample size increases the likelihood of finding a statistically significant difference if one exists in the population.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "The results of the hypothesis testing indicate that the decision regarding the fairness of the coin depends on the sample size. For smaller sample sizes (30 and 100), we fail to reject the null hypothesis, suggesting that the coin is fair. However, for a larger sample size (1000), we reject the null hypothesis, indicating that the coin is likely unfair.\n",
    "\n",
    "Increasing the sample size improves the accuracy and power of the hypothesis test, making it more likely to detect deviations from the null hypothesis if they exist in the population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of group 1: 30.0\n",
      "Mean of group 2: 31.1\n",
      "Pooled standard deviation: 2.9145230217729363\n",
      "t-statistic: -0.8439373293244824\n",
      "p-value: 0.4097807011627439\n",
      "p-value: 0.4097807011627439 >= alpha: 0.05\n",
      "Fail to reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "group1 = np.array([25, 30, 28, 35, 34, 30, 28, 32, 31, 27])\n",
    "group2 = np.array([27, 32, 30, 36, 33, 31, 29, 33, 32, 28])\n",
    "\n",
    "mean_group1 = np.mean(group1)\n",
    "mean_group2 = np.mean(group2)\n",
    "\n",
    "std_group1 = np.std(group1, ddof=1)\n",
    "std_group2 = np.std(group2, ddof=1)\n",
    "\n",
    "pooled_std = np.sqrt(((len(group1) - 1) * std_group1**2 + (len(group2) - 1) * std_group2**2) / (len(group1) + len(group2) - 2))\n",
    "\n",
    "t_statistic = (mean_group1 - mean_group2) / (pooled_std * np.sqrt(1/len(group1) + 1/len(group2)))\n",
    "\n",
    "print(f\"Mean of group 1: {mean_group1}\")\n",
    "print(f\"Mean of group 2: {mean_group2}\")\n",
    "print(f\"Pooled standard deviation: {pooled_std}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "\n",
    "\n",
    "df = len(group1) + len(group2) - 2\n",
    "p_value = stats.t.sf(np.abs(t_statistic), df) * 2 \n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"p-value: {p_value} < alpha: {alpha}\")\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(f\"p-value: {p_value} >= alpha: {alpha}\")\n",
    "    print(\"Fail to reject the null hypothesis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Analysis:\n",
    "\n",
    "- **Mean of group 1**: \\(30.0\\)\n",
    "- **Mean of group 2**: \\(31.1\\)\n",
    "- **Pooled standard deviation**: \\(2.9145\\)\n",
    "- **t-statistic**: \\(-0.8439\\)\n",
    "- **p-value**: \\(0.4098\\)\n",
    "\n",
    "#### Decision:\n",
    "\n",
    "- **p-value**: \\(0.4098\\) is greater than \\(0.05\\) (\\( \\alpha \\))\n",
    "- **Conclusion**: Fail to reject the null hypothesis\n",
    "\n",
    "### Discussion:\n",
    "\n",
    "The hypothesis test comparing the means of group 1 and group 2 results in a t-statistic of \\(-0.8439\\) and a p-value of \\(0.4098\\). Since the p-value is greater than the significance level (\\( \\alpha = 0.05 \\)), we fail to reject the null hypothesis.\n",
    "\n",
    "The null hypothesis typically posits that there is no difference between the means of the two groups. In this case, the result suggests that there is not enough evidence to conclude that the means of the two groups are different at the \\(0.05\\) significance level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Job Placement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the t-statistic and degrees of freedom for the two groups (\"Placed\" and \"Not Placed\") without using any libraries, you can follow the formulas provided earlier. Here's how you can do it:\n",
    "\n",
    "#### Formulas:\n",
    "\n",
    "1. **Mean (Average)**:\n",
    "$$\n",
    "\\text{Mean} = \\frac{\\text{Sum of all values}}{\\text{Number of values}}\n",
    "$$\n",
    "\n",
    "2. **Variance**:\n",
    "$$\n",
    "\\text{Variance} = \\frac{\\sum_{i=1}^{n} (x_i - \\text{Mean})^2}{n}\n",
    "$$\n",
    "\n",
    "3. **Standard Deviation (Sample)**:\n",
    "$$\n",
    "\\text{Standard Deviation (Sample)} = \\sqrt{\\text{Variance}}\n",
    "$$\n",
    "\n",
    "4. **Pooled Standard Deviation**:\n",
    "$$\n",
    "\\text{Pooled Standard Deviation} = \\sqrt{\\frac{(n_1 - 1) \\times \\text{SD}_1^2 + (n_2 - 1) \\times \\text{SD}_2^2}{n_1 + n_2 - 2}}\n",
    "$$\n",
    "\n",
    "5. **t-statistic**:\n",
    "$$\n",
    "\\text{t-statistic} = \\frac{\\text{Mean}_1 - \\text{Mean}_2}{\\text{Pooled Standard Deviation} \\times \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n",
    "$$\n",
    "\n",
    "6. **Degrees of Freedom**:\n",
    "$$\n",
    "\\text{Degrees of Freedom} = n_1 + n_2 - 2\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"job_placement.csv\")\n",
    "\n",
    "place = data.where(data['placement_status']==\"Placed\").dropna()['gpa']\n",
    "place.reset_index(drop=True, inplace=True)\n",
    "\n",
    "not_placed = data.where(data['placement_status']==\"Not Placed\").dropna()['gpa']\n",
    "not_placed.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of 'Placed' group: 3.7615114235500884\n",
      "Mean of 'Not Placed' group: 3.702307692307692\n",
      "Pooled standard deviation: 0.11915778014140557\n",
      "t-statistic: 5.111117864032126\n",
      "Degrees of Freedom: 697\n"
     ]
    }
   ],
   "source": [
    "mean_placed = place.mean()\n",
    "var_placed = place.var()\n",
    "n_placed = len(place)\n",
    "\n",
    "mean_not_placed = not_placed.mean()\n",
    "var_not_placed = not_placed.var()\n",
    "n_not_placed = len(not_placed)\n",
    "\n",
    "sd_place = var_placed ** 0.5\n",
    "sd_not_placed = var_not_placed ** 0.5\n",
    "\n",
    "df = n_placed + n_not_placed - 2\n",
    "\n",
    "pooled_sd = s_pooled = (((n_placed - 1) * var_placed + (n_not_placed - 1) * var_not_placed) / df) ** 0.5\n",
    "\n",
    "t_statistic = (mean_placed - mean_not_placed) / (pooled_sd * ((1 / n_placed + 1 / n_not_placed) ** 0.5))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean of 'Placed' group: {mean_placed}\")\n",
    "print(f\"Mean of 'Not Placed' group: {mean_not_placed}\")\n",
    "print(f\"Pooled standard deviation: {pooled_sd}\")\n",
    "print(f\"t-statistic: {t_statistic}\")\n",
    "print(f\"Degrees of Freedom: {df}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 4.140880583322707e-07\n",
      "p-value: 4.140880583322707e-07 < alpha: 0.05\n",
      "Reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "p_value = stats.t.sf(abs(t_statistic), df) * 2\n",
    "\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(f\"p-value: {p_value} < alpha: {alpha}\")\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(f\"p-value: {p_value} >= alpha: {alpha}\")\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=5.111117864032125, pvalue=4.140880583334006e-07, df=697.0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(place, not_placed, equal_var=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications of Monte Carlo Simulation:\n",
    "\n",
    "1. **Finance and Risk Analysis**: Monte Carlo simulation is extensively used in finance for risk assessment and portfolio optimization. It can simulate thousands of possible scenarios to predict the probability of various financial outcomes, such as the potential returns and risks associated with different investment portfolios.\n",
    "\n",
    "2. **Engineering and Design**: In engineering, Monte Carlo simulation can be used for reliability analysis, design optimization, and performance prediction of complex systems and structures. It helps engineers identify potential failure points, optimize designs, and make informed decisions based on probabilistic outcomes.\n",
    "\n",
    "3. **Healthcare and Medicine**: Monte Carlo simulation is used in healthcare for clinical trials, drug development, and treatment planning. It can simulate the effects of different treatments and interventions on patient outcomes, helping researchers and clinicians make evidence-based decisions and predictions.\n",
    "\n",
    "4. **Energy and Utilities**: In the energy sector, Monte Carlo simulation can be applied to evaluate the performance and reliability of power generation systems, optimize energy production, and assess the risks associated with energy investments and operations.\n",
    "\n",
    "5. **Project Management**: Monte Carlo simulation can be used in project management to assess the likelihood of completing projects on time and within budget. It can simulate various project scenarios, identify critical tasks, and help project managers allocate resources more effectively.\n",
    "\n",
    "6. **Environmental Modeling**: Monte Carlo simulation is employed in environmental science and engineering to simulate natural processes, assess environmental risks, and evaluate the impact of human activities on ecosystems. It can help researchers and policymakers make informed decisions about environmental management and conservation strategies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of sample size in part 2:\n",
    "\n",
    "- the sample size has a significant impact on the Central Limit Theorem. As the sample size increases, the distribution of sample means converges to a normal distribution, the variability decreases, and the accuracy of estimates improves. Understanding and considering the role of sample size is essential for applying the Central Limit Theorem effectively in statistical analyses and research.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
