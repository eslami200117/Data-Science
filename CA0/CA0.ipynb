{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping and Introductory Data Analysis\n",
    "// purpose of assintment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// summary of what we're going to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r ./../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_BLOCKS = 3\n",
    "ETHERESCAN_URL = \"https://etherscan.io/txs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EthereumScraping:\n",
    "    url = ETHERESCAN_URL\n",
    "    columns = ['tnx_hash', 'method', 'block', 'date', 'from', 'to', 'value', 'tnx_fee']\n",
    "\n",
    "    def __init__(self, number_block: int=10) -> None:\n",
    "        self.number_block = number_block\n",
    "        self.driver = None\n",
    "        self.df = pd.DataFrame(columns=self.columns)\n",
    "\n",
    "    def __del__(self) -> None:\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "\n",
    "    def _get_data_from_td_tag(self, element: bs4.element.Tag) -> str:\n",
    "        return element.find('a').get('href').split('/')[-1] \n",
    "\n",
    "    def _collect_data_from_tr_tag(self, elements: bs4.element.ResultSet)-> pd.core.series.Series:\n",
    "        return pd.Series(\n",
    "            [\n",
    "                elements[1].text.strip(),\n",
    "                elements[2].text.strip(),\n",
    "                elements[3].text.strip(),\n",
    "                elements[4].text.strip(),\n",
    "                self._get_data_from_td_tag(elements[7]),\n",
    "                self._get_data_from_td_tag(elements[9]),\n",
    "                elements[10].text.strip(),\n",
    "                elements[11].text.strip()\n",
    "            ],\n",
    "            index=self.columns\n",
    "\n",
    "        ), int(elements[3].text.strip())\n",
    "\n",
    "\n",
    "    def _extract_data_from_html(self, html_content: str) -> int:\n",
    "        soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "        rows = soup.find_all(\"tr\")\n",
    "        block_number = 0\n",
    "        for row in rows:\n",
    "            cells = row.find_all(\"td\")\n",
    "            series, block = self._collect_data_from_tr_tag(cells)\n",
    "            block_number = max(block_number, block)\n",
    "            self.df = pd.concat([self.df, pd.DataFrame([series])], ignore_index=True)\n",
    "\n",
    "        return block_number\n",
    "\n",
    "            \n",
    "    def _extract_data_from_url(self) -> int:\n",
    "        return self._extract_data_from_html(\n",
    "            self.driver.find_element(\n",
    "                By.CSS_SELECTOR, \"tbody.align-middle.text-nowrap\"\n",
    "            ).get_attribute(\"outerHTML\")\n",
    "        )\n",
    "    \n",
    "    def _click_next_button(self) -> None:\n",
    "        try:\n",
    "            WebDriverWait(self.driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"a[aria-label='Next']\"))\n",
    "            ).click()\n",
    "        except Exception as e:\n",
    "            print(f\"Error clicking the 'Next' button: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _extract_data(self) -> None:\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.driver.get(self.url)\n",
    "        block_number = new_block_number  = self._extract_data_from_url()\n",
    "        while (block_number - new_block_number) < self.number_block:\n",
    "            self._click_next_button()\n",
    "            new_block_number = self._extract_data_from_url()\n",
    "        \n",
    "    def get_data(self) -> pd.core.frame.DataFrame:\n",
    "        self._extract_data()\n",
    "        return self.df\n",
    "        \n",
    "      \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripEther = EthereumScraping(NUMBER_BLOCKS)\n",
    "df = scripEther.get_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
